{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\nTutorial 2: Customizing and aligning gradients\n=================================================\nIn this tutorial you\u2019ll learn about the methods available within the\nGradientMaps class. The flexible usage of this class allows for the\ncustomization of gradient computation with different kernels and dimensionality\nreductions, as well as aligning gradients from different datasets.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As before, we\u2019ll start by loading the sample data.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import warnings\nwarnings.simplefilter('ignore')\n\nfrom brainspace.datasets import load_group_hcp, load_parcellation, load_conte69\n\n# First load mean connectivity matrix and Schaefer parcellation\nconn_matrix = load_group_hcp('schaefer', n_parcels=400)\nlabeling = load_parcellation('schaefer', n_parcels=400)\nmask = labeling != 0\n\n# and load the conte69 hemisphere surfaces\nsurf_lh, surf_rh = load_conte69()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The GradientMaps object allows for many different kernels and dimensionality\nreduction techniques. Let\u2019s have a look at three different kernels.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\n\nfrom brainspace.gradient import GradientMaps\nfrom brainspace.plotting import plot_hemispheres\nfrom brainspace.utils.parcellation import map_to_labels\n\nkernels = ['pearson', 'spearman', 'normalized_angle']\n\ngradients_kernel = [None] * len(kernels)\nfor i, k in enumerate(kernels):\n    gm = GradientMaps(kernel=k, approach='dm', random_state=0)\n    gm.fit(conn_matrix)\n\n    gradients_kernel[i] = map_to_labels(gm.gradients_[:, i], labeling,\n                                        mask=mask, fill=np.nan)\n\n\nplot_hemispheres(surf_lh, surf_rh, array_name=gradients_kernel,\n                 size=(800, 450), cmap_name='viridis')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "It seems the gradients provided by these kernels are quite similar although\ntheir scaling is quite different. Do note that the gradients are in arbitrary\nunits, so the smaller/larger axes across kernels do not imply anything.\nSimilar to using different kernels, we can also use different dimensionality\nreduction techniques.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "embeddings = ['pca', 'le', 'dm']\n\ngradients_embedding = [None] * len(embeddings)\nfor i, emb in enumerate(embeddings):\n    gm = GradientMaps(kernel='normalized_angle', approach=emb, random_state=0)\n    gm.fit(conn_matrix)\n\n    gradients_embedding[i] = map_to_labels(gm.gradients_[:, i], labeling,\n                                           mask=mask, fill=np.nan)\n\n\nplot_hemispheres(surf_lh, surf_rh, array_name=gradients_embedding,\n                 size=(800, 452), cmap_name='viridis')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here we do see some substantial differences: PCA appears to find a slightly\ndifferent axis, with the somatomotor in the middle between default mode and\nvisual, whereas LE and DM both find the canonical first gradient but their\nsigns are flipped. Fortunately, the sign of gradients is arbitrary, so we\ncould simply multiply either the LM and DM gradient by -1 to make them more\ncomparable.\n\nA more principled way of increasing comparability across gradients are\nalignment techniques. BrainSpace provides two alignment techniques:\nProcrustes analysis, and joint alignment. For this example we will load\nfunctional connectivity data of a second subject group and align it with the\nfirst group.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from brainspace.datasets import load_holdout_hcp\n\nconn_matrix2 = load_holdout_hcp('schaefer', 400)\ngp = GradientMaps(kernel='normalized_angle', alignment='procrustes')\ngj = GradientMaps(kernel='normalized_angle', alignment='joint')\n\ngp.fit([conn_matrix2, conn_matrix])\ngj.fit([conn_matrix2, conn_matrix])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here, `gp` contains the Procrustes aligned data and `gj` contains the joint\naligned data. Let\u2019s plot them, but in separate figures to keep things\norganized.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# First gradient from holdout and original data\ngradients_unaligned = [None] * 2\nfor i in range(2):\n    gradients_unaligned[i] = map_to_labels(gp.gradients_[i][:, 0], labeling,\n                                           mask=mask, fill=np.nan)\n\nplot_hemispheres(surf_lh, surf_rh, array_name=gradients_unaligned,\n                 size=(800, 300), cmap_name='viridis')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "gradients_procrustes = [None] * 2\nfor i in range(2):\n    gradients_procrustes[i] = map_to_labels(gp.aligned_[i][:, 0], labeling,\n                                            mask=mask, fill=np.nan)\n\nplot_hemispheres(surf_lh, surf_rh, array_name=gradients_procrustes,\n                 size=(800, 300), cmap_name='viridis')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "gradients_joint = [None] * 2\nfor i in range(2):\n    gradients_joint[i] = map_to_labels(gj.aligned_[i][:, 0], labeling,\n                                       mask=mask, fill=np.nan)\n\nplot_hemispheres(surf_lh, surf_rh, array_name=gradients_joint,\n                 size=(800, 300), cmap_name='viridis')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Before gradient alignment, the first gradient is reversed, but both\nalignments resolve this issue. If the input data was less similar, alignments\nmay also resolve changes in the order of the gradients. However, you should\nalways inspect the output of an alignment; if the input data are sufficiently\ndissimilar then the alignment may produce odd results.\n\nThat concludes the second tutorial. In the third tutorial we will consider\nnull hypothesis testing of comparisons between gradients and other markers.\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}